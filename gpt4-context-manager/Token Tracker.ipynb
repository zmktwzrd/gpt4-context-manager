{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "import base64\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "api_key = \"YOUR API KEY HERE\"\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "token_limit = 128000\n",
    "summary_ratio = 0.5\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are GPT-4 Turbo. Start with 'How may I assist you today?'\"}\n",
    "conversation = [system_message]\n",
    "\n",
    "def calculate_tokens(messages):\n",
    "    total_tokens = 0\n",
    "    for message in messages:\n",
    "        total_tokens += 4\n",
    "        total_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return total_tokens + 2\n",
    "\n",
    "def get_chatgpt_response(messages):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=messages,\n",
    "            max_tokens=4000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        response_text = response.choices[0].message.content\n",
    "        cleaned_response = response_text.replace(\"Understood. \", \"\")\n",
    "        return cleaned_response\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "def summarize_conversation(ratio=0.5):\n",
    "    current_tokens = calculate_tokens(conversation)\n",
    "    target_tokens = int(current_tokens * ratio)\n",
    "    summary_prompt = [\n",
    "        {\"role\": \"system\", \"content\": f\"Summarize this conversation to approximately {target_tokens} tokens while preserving key details:\"},\n",
    "        {\"role\": \"user\", \"content\": \" \".join([msg['content'] for msg in conversation])}\n",
    "    ]\n",
    "    response = get_chatgpt_response(summary_prompt)\n",
    "    return response\n",
    "\n",
    "def process_document(file_path):\n",
    "    text = read_file(file_path)\n",
    "    if text.startswith(\"Error\"): return text\n",
    "    \n",
    "    tokens_used = len(encoding.encode(text))\n",
    "    print(f\"Document tokens: {tokens_used}\")\n",
    "    \n",
    "    max_chunk_size = 32000\n",
    "    chunks = [text[i:i+max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
    "    \n",
    "    full_response = \"\"\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"Processing chunk {i}/{len(chunks)}...\")\n",
    "        conversation.append({\"role\": \"user\", \"content\": f\"Analyze this text: {chunk}\"})\n",
    "        response = get_chatgpt_response(conversation)\n",
    "        full_response += response + \"\\n\"\n",
    "        conversation.pop()\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "def process_image(image_path):\n",
    "    try:\n",
    "        image_path = image_path.strip('\"').strip(\"'\")\n",
    "        with open(image_path, \"rb\") as img_file:\n",
    "            base64_image = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Analyze the content of this image.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                ]\n",
    "            }],\n",
    "            max_tokens=4000\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image: {str(e)}\"\n",
    "\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        file_path = file_path.strip('\"').strip(\"'\")\n",
    "        \n",
    "        if file_path.lower().endswith('.pdf'):\n",
    "            with open(file_path, 'rb') as file:\n",
    "                return \"\".join(page.extract_text() or \"\" for page in PdfReader(file).pages)\n",
    "        elif file_path.lower().endswith('.docx'):\n",
    "            return \" \".join(paragraph.text for paragraph in Document(file_path).paragraphs)\n",
    "        elif file_path.lower().endswith('.txt'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        else:\n",
    "            return f\"Unsupported format: {os.path.splitext(file_path)[1]}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "def start_conversation():\n",
    "    print(\"GPT-4 Token Tracker Initialized.\")\n",
    "    print(\"Commands:\")\n",
    "    print(\"- doc <path> (Upload a document for analysis)\")\n",
    "    print(\"- image <path> (Upload an image for analysis)\")\n",
    "    print(\"- summary <ratio> (Summarize conversation, e.g., summary 0.5)\")\n",
    "    print(\"- exit/quit (Exit the session)\")\n",
    "    print(\"How may I assist you today?\")  # Display initial prompt\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]: \n",
    "            print(\"Exiting conversation.\")\n",
    "            break\n",
    "            \n",
    "        print(f\"You: {user_input}\")  # Display user input in the terminal\n",
    "\n",
    "        if user_input.lower().startswith(\"doc \"):\n",
    "            file_path = user_input[4:].strip()\n",
    "            response = process_document(file_path)\n",
    "            print(f\"GPT-4: {response}\")\n",
    "        elif user_input.lower().startswith(\"image \"):\n",
    "            image_path = user_input[6:].strip()\n",
    "            response = process_image(image_path)\n",
    "            print(f\"GPT-4: {response}\")\n",
    "        elif user_input.lower().startswith(\"summary \"):\n",
    "            try:\n",
    "                ratio = float(user_input[8:].strip())\n",
    "                summary = summarize_conversation(ratio)\n",
    "                conversation.clear()\n",
    "                conversation.append(system_message)\n",
    "                conversation.append({\"role\": \"system\", \"content\": summary})\n",
    "                print(\"Conversation summarized.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid ratio. Use a decimal (e.g., 0.5 for 50%).\")\n",
    "        else:\n",
    "            conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "            current_tokens = calculate_tokens(conversation)\n",
    "            print(f\"Current tokens: {current_tokens}\")\n",
    "            \n",
    "            response = get_chatgpt_response(conversation)\n",
    "            conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "            print(f\"GPT-4: {response}\")\n",
    "            \n",
    "            current_tokens = calculate_tokens(conversation)\n",
    "            print(f\"Updated tokens: {current_tokens}\")\n",
    "            \n",
    "            if current_tokens > token_limit - 1000:\n",
    "                print(f\"Approaching limit. Summarizing to {summary_ratio*100}%.\")\n",
    "                summary = summarize_conversation(summary_ratio)\n",
    "                conversation.clear()\n",
    "                conversation.append(system_message)\n",
    "                conversation.append({\"role\": \"system\", \"content\": summary})\n",
    "                current_tokens = calculate_tokens(conversation)\n",
    "                print(f\"New token count after summary: {current_tokens}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_conversation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
